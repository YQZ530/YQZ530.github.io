<!doctype html>
<html>
<!-- InstanceBegin template="GeneralPage.dwt" codeOutsideHTMLIsLocked="false" -->
<head>
<meta charset="UTF-8" >
<!-- InstanceBeginEditable name="doctitle" -->
<title>Yongqi Zhang</title>
<!-- InstanceEndEditable -->
<!-- InstanceBeginEditable name="head" -->
<link href="style.css" rel="stylesheet" type="text/css">
<!-- InstanceEndEditable -->

<!--The following script tag downloads a font from the Adobe Edge Web Fonts server for use within the web page. We recommend that you do not modify it.--> 
<script>var __adobewebfontsappname__="dreamweaver"</script> 
<script src="http://use.edgefonts.net/bilbo:n4:default.js" type="text/javascript"></script>
</head>

<body>
<header>
  <div class="titlename"><strong>Yongqi Zhang</strong></div> 
  <div class="body-header-div"> 
  <a href="index.html" class="nav">Home</a>&nbsp;&nbsp;&nbsp;&nbsp; 
    <!-- <a href="publications.html" class="nav">Publications</a>&nbsp;&nbsp;&nbsp;&nbsp; -->
    <!-- <a href="about.html" class="nav">Team</a>&nbsp;&nbsp;&nbsp;&nbsp;  -->
  <a href ="./CV/YZ_CV.pdf" class="nav" target="new">CV</a>&nbsp;&nbsp;&nbsp;&nbsp; 
  <a href="./public/index.html" class="nav" target="new">Publication</a></div> 
  <!-- <a href="https://scholar.google.com/citations?view_op=search_authors&mauthors=YY&hl=en&oi=ao" class="nav" target="new">Google Scholar</a></div> -->
</header>
<main> <!-- InstanceBeginEditable name="EditRegion Main" --> 
  
  <!-- About me page -->
  <div>
    <table border="0" width="800" align="center">
      <tbody>
        <tr>
          <td><img src="src/profile.jpg"  height="250" style="float:left" alt=""/></td>
          <td valign="top">
               CS PhD student in <a href="https://cs.gmu.edu/" target="new"> George Mason University</a><br>
                <p> Currently, I am working at the Design Computing and eXtended Reality (DCXR) group with 
                  my advisor <a href="https://craigyuyu.github.io/home/index.html" target="new">Prof. Craig Yu</a>. 
                My research interests include VR, computational design and  HCI, particularly on the applying computational technique and artificial intelligence techniques 
                for creating personalized virtual experience and scenes. My research has been published in IEEE VR and ACM CHI; 
                and was recognized with a <a href="https://chi2019.acm.org/2019/03/15/chi-2019-best-papers-honourable-mentions/">Best Paper Honorable Mention Award at CHI 2019</a>. 
              </p>
              <p> In the summer of 2022, I interned at Adobe's Creative Intelligence Lab under the mentorship of <a href = "https://research.adobe.com/person/cuong-nguyen/" target = "new"> Cuong Nguyen</a> 
                and <a href = "https://rubaiathabib.me/" target = "new" > Rubaiat Habib </a>.
              </p>
              
              Email: <a href="mailto:yzhang59@gmu.edu">yzhang59@gmu.edu</a><br>
              </p>
          </td>
          <td><img src="src/thumbnails/gmu.png" height="100" alt=""/></td>
          <td><img src="src/thumbnails/DCXR.png"  height="100" alt=""/></td>
          <td align="right"><img src="thumbnails/Logo.png" height="150" alt=""/></td>
        </tr>
      </tbody>
    </table>
  </div>
  
 
  
  
  <!-- Publication -->
  <div>
    <table border="0" width="800" align="center" >
      <tbody>
        <tr>
          <td><h1>Publication</h1></td>
        </tr>
      </tbody>
    </table>
  </div>
  <hr width="800">

  <!-- Mixed-Integer Programming for Adaptive VR Workflow Training-->
  <div>
<table border="0">
  <tbody>
    <tr>
      <td><img src="src/thumbnails/vrtraining.gif" width="200"  alt=""/></td>
      <!-- title -->
      <td valign="top"><strong><em> Mixed-Integer Programming for Adaptive VR Workflow Training </em></strong><br>
        <! -- &nbsp;&nbsp;&nbsp; for indentation -->
        <!-- authors  --> 
      <strong>Yongqi Zhang</strong>, Chuan Yan, Haikun Huang, Simon Su, Lap-Fai Yu<br> 
        
        
        <!-- summary --> 
        Generate Adaptive training content for VR <br>
        
        <!-- keys --> 
        <a class="keyword">Game design | Optimizatin | Adaptive training</a> <br>
        <a class="venue">International Conference on Human-Computer Interaction (HCII), 2024 </a> <br>
       
        <!-- links --> 
        <a href="paper/vrtraining.pdf" target="new">Paper</a> | <a href="https://youtu.be/ZmRH4Bv5xWU" target="new">Video</a> |
        <a href="./vrtraining.html" target="new">Project Page</a> 
    </tr>
  </tbody>
</table>
</div>



  <!-- PoseVEC: Authoring Adaptive Pose-aware Effects using Visual Programming and Demonstrations-->
  <div>
<table border="0">
  <tbody>
    <tr>
      <td><img src="src/thumbnails/arlens.gif" width="200"  alt=""/></td>
      <!-- title -->
      <td valign="top"><strong><em> PoseVEC: Authoring Adaptive Pose-aware Effects 
        <br> using Visual  Programming and Demonstrations </em></strong><br>
        <! -- &nbsp;&nbsp;&nbsp; for indentation -->
        <!-- authors  --> 
      <strong>Yongqi Zhang</strong>, Cuong Nguyen, Rubaiat Habib Kazi, Lap-Fai Yu<br> 
        
        
        <!-- summary --> 
        Toolkit for authoring Adaptive Pose-aware Effects <br>
        
        <!-- keys --> 
        <a class="keyword">Visual Effects Authoring | Motion Graphics | Programming by Demonstration</a> <br>
        
        <!-- venue --> 
        <a class="venue">The ACM Symposium on User Interface Software and Technology (<strong>UIST 2023</strong>) </a> <br>
        
        <!-- links --> 
        <a href="paper/UIST23.pdf" target="new">Paper</a> | <a href="https://youtu.be/5Od8u77GEYs" target="new">Video</a> |
        <a href="./arlens.html" target="new">Project Page</a> 
    </tr>
  </tbody>
</table>
</div>

  
  <!-- Joint Computational Design of Workspaces and Workplans -->
 
<div>
<table border="0">
  <tbody>
    <tr>
      <td><img src="src/thumbnails/workplace.gif" width="200"  alt=""/></td>
      <!-- title -->
      <td valign="top"><strong><em>Joint Computational Design of Workspaces and Workplans</em></strong><br>
        
        <!-- authors  --> 
      <strong>Yongqi Zhang</strong>, Haikun Huang, Erion Plaku, Lap-Fai Yu<br> 
        
        
        <!-- summary --> 
        Computational design for workplaces. <br>
        
        <!-- keys --> 
        <a class="keyword">Layout Design| Computational Design| Personalization</a> <br>
        
        <!-- venue --> 
        <a class="venue">ACM Transactions on Graphics (Proceeding of <strong>SIGGRAPH Asia 2021</strong>) </a> <br>
        
        <!-- links --> 
        <a href="./public/publication/workplace/index.html" target="new">Project Page</a> 
        | <a href="paper/workplace.pdf" target="new">Paper</a>| <a href="https://youtu.be/xP3OhUE8XVs" target="new">Video</a> |  <a href="bibtex.txt" target="new">Bibtex</a></td>
    </tr>
  </tbody>
</table>
</div>


<div>
<table border="0">
  <tbody>
    <tr>
      <td><img src="src/thumbnails/vrtraining.PNG" width="200"  alt=""/></td>
      <!-- title -->
      <td valign="top"><strong><em>A Review on Virtual Reality Skill Training Applications</em></strong><br>
        
        <!-- authors --> 
       Biao Xie, Huimin Liu, Rawan Alghofaili,<strong>Yongqi Zhang </strong>,Yeling Jiang, <br>
       Flavio Destri Lobo,Changyang Li, Wanwan Li, Haikun Huang, Mesut Akdere, <br>
       Christos Mousas, Lap-Fai Yu<br> 
        
        
        <!-- summary --> 
        Virtual Reality technology for different training application. <br>
        
        <!-- keys --> 
        <a class="keyword">Virtual Reality, Training| Simulation| Content creation | Personalization</a> <br>
        
        <!-- venue --> 
        <a class="venue">Frontiers in Virtual Reality, 2021</a> <br>
        
        <!-- links --> 
        <a href="https://www.frontiersin.org/articles/10.3389/frvir.2021.645153/full" target="new">Project Page</a> | <a href="paper/Frontiers2021.pdf" target="new">Paper</a> | <a href="bibtex.txt" target="new">Bibtex</a></td>
    </tr>
  </tbody>
</table>
</div>


    <!-- Toward Automatic Audio Description Generation for Accessible Videos -->

    <div>
    <table border="0">
      <tbody>
        <tr>
          <td><img src="src/thumbnails/audio.png" width="200"  alt=""/></td>
          <!-- title -->
          <td valign="top"><strong><em>Toward Automatic Audio Description Generation for Accessible Videos</em></strong><br>
            
            <!-- authors --> 
            Yujia Wang, Wei Liang, Haikun Huang,<strong>Yongqi Zhang</strong>, Dingzeyu Li, Lap-Fai Yu<br>
            
            <!-- summary --> 
             Audio Description Generation for Accessible Videos and Survey. <br>
            
            <!-- keys --> 
            <a class="keyword">Human-centered computing | Accessibility systems</a> <br>
            
            <!-- venue --> 
            <a class="venue">Proceedings of the ACM Conference on Human Factors in Computing Systems (<strong>CHI 2020</strong>)</a> <br>
            
            <!-- links --> 
            <a href="https://bitwangyujia.github.io/research/project/ad.html" target="new">Project Page</a> | <a href="paper/SIGCHI2021-ad.pdf" target="new">Paper</a> | <a href="https://www.youtube.com/watch?v=VbAe-0_SNXg" target="new">Video</a> | <a href="bibtex.txt" target="new">Bibtex</a></td>
        </tr>
      </tbody>
    </table>
  </div>
   


  <!-- Exertion-Aware Path Generation -->
  <div>
    <table border="0">
      <tbody>
        <tr>
          <td><img src="src/thumbnails/level3.png" width="200"  alt=""/></td>
          <!-- title -->
          <td valign="top"><strong><em>Exertion-Aware Path Generation</em></strong><br>
            
            <!-- authors --> 
            *Wanwan Li, *Biao Xie, <strong>Yongqi Zhang</strong>, Walter Meiss, Haikun Huang, Lap-Fai Yu<br>
            *Equal contributors<br>
            
            <!-- summary --> 
            Generating exertion-aware paths over 3D terrains for VR exercising.<br>
            
            <!-- keys --> 
            <a class="keyword">Procedural Modeling | Level Design | Path Generation | Haptics</a> <br>
            
            <!-- venue --> 
            <a class="venue">ACM Transactions on Graphics (Proceeding of <strong>SIGGRAPH 2020</strong>)</a> <br>
            
            <!-- links --> 
            <a href="https://craigyuyu.github.io/home/project_pages/exertion/exertion.html" target="new">Project Page</a> | <a href="paper/level3_low.pdf" target="new">Paper</a> | <a href="https://www.youtube.com/watch?v=0SGnlEWescU" target="new">Video</a> | <a href="bibtex.txt" target="new">Bibtex</a></td>
        </tr>
      </tbody>
    </table>
  </div>
  <br>
  <!-- Pose-Guided Level Design -->
  <div>
    <table border="0">
      <tbody>
        <tr>
          <td><img src="src/thumbnails/level2_optimized.gif" width="200"  alt=""/></td>
          <!-- title -->
          <td valign="top"><strong><em>Pose-Guided Level Design</em></strong><br>
            
            <!-- authors --> 
            <strong>*Yongqi Zhang</strong>, *Biao Xie, Haikun Huang, Elisa Ogawa, Tongjian You, Lap-Fai Yu<br>
            *Equal contributors<br>
            
            <!-- summary --> 
            Procedural game level generator for motion/exercise games (e.g., Just Dance, Speed of Light).<br>
            
            <!-- keys --> 
            <a class="keyword">Level Design | Optimization | Exergaming | Generative Designv</a> <br>
            
            <!-- venue --> 
            <a class="venue">Proceedings of the ACM Conference on Human Factors in Computing Systems (<strong>CHI 2019</strong>)</a> <br>
			  
			  <!-- Award -->
			<a href="https://chi2019.acm.org/2019/03/15/chi-2019-best-papers-honourable-mentions/" target="new">CHI 2019 Honourable Mentions Award</a><br>
            
            <!-- links http://blogs.umb.edu/yongqizhang001/pose-guided-level-design/  --> 
            <a href="./public/publication/level2/index.html" target="new">Project Page</a> | <a href="paper/level2.pdf" target="new">Paper</a> | <a href="https://www.youtube.com/watch?v=uRqwKZWw6Fo&feature=youtu.be" target="new">Video</a> | <a href="bibtex.txt" target="new">Bibtex</a></td>
        </tr>
      </tbody>
    </table>
  </div>
	<br>
	
	<!-- Exercise Intensity-driven Level Design -->
  <div>
    <table border="0">
      <tbody>
        <tr>
          <td><img src="src/thumbnails/exergame.gif" width="200"  alt=""/></td>
          <!-- title -->
          <td valign="top"><strong><em>Exercise Intensity-driven Level Design</em></strong><br>
            
            <!-- authors --> 
            Biao Xie*, <strong>Yongqi Zhang*</strong>, Haikun Huang, Elisa Ogawa, Tongjian You, Lap-Fai Yu<br>
            *Equal contributors<br>
            
            <!-- summary --> 
            Procedural generating exergame level with repect to some exercise goals(e.g.,Reflex, LongBow)<br>
            
            <!-- keys --> 
            <a class="keyword">Level Design | Optimization | Exergaming | Generative Design</a> <br>
            
            <!-- venue --> 
            <a class="venue">IEEE Transactions on Visualization and Computer Graphics (TVCG), 2018 (<strong>Special Issue on IEEE Virtual Reality 2018</strong>)</a> <br>
		
			  
			  <!-- Award -->
			<a href="https://innovate.ieee.org/innovation-spotlight/vr-games-exercise-intensity-level-design-plug-in/" target="new">Featured on IEEE Xplore Innovation Spotlight</a><br>
            
            <!-- links  https://biaoxie.github.io/home/projects/level1/level1.html -->   
            <a href="./public/publication/level1/index.html" target="new">Project Page</a> | <a href="paper/level.pdf" target="new">Paper</a> | <a href="https://www.youtube.com/watch?v=I2JvVL1dW3s" target="new">Video</a> | <a href="bibtex.txt" target="new">Bibtex</a></td>
        </tr>
      </tbody>
    </table>
  </div>
	<br>
  
  <!-- Honors & Awards -->
  <div>
    <table border="0" width="800" align="center" >
      <tbody>
        <tr>
          <td><h1>Honors & Awards</h1></td>
        </tr>
      </tbody>
    </table>
  </div>
  <hr width="800">
  <div>
    <table width="800" border="0" align="center">
      <tbody>
        <tr>
          <td><li>NSF Graduate Research Fellowship 2019</li>
            <li><a href="https://chi2019.acm.org/2019/03/15/chi-2019-best-papers-honourable-mentions/" target="new">Best Paper Honorable Mention Award, CHI 2019</a></li></td>
        </tr>
      </tbody>
    </table>
  </div>
  
  <!-- Services -->
  <div>
    <table border="0" width="800" align="center" >
      <tbody>
        <tr>
          <td><h1>Services</h1></td>
        </tr>
      </tbody>
    </table>
  </div>
  <hr width="800">
  <table width="800" border="0" align="center">
    <tbody>
      <tr>
        <td><!-- -->
	
           <li>Reviewer, CHI 2021 </li>
          <li>Reviewer, IEEE VR 2021 </li>
		
         
      </tr>
    </tbody>
  </table>
  
  <!-- In the Press -->
  <div>
    <table border="0" width="800" align="center" >
      <tbody>
        <tr>
          <td><h1>In the Press</h1></td>
        </tr>
      </tbody>
    </table>
  </div>
  <hr width="800">
  <table width="800" border="0" align="center">
    <tbody>
      <tr>
        <td><li><a href="http://ieeexplore-spotlight.ieee.org/article/vr-games-exercise-intensity-level-design-plug-in/" target="new">"Do VR Games Wear You Out? New Plug-In Helps Developers Personalize Exercise Intensity", IEEE Xplore Innovation Spotlight Headline, 2018</a></li>
         </td>
      </tr>
    </tbody>
  </table>
  
 
  
 

 
  <!-- InstanceEndEditable --> </main>
<!--	<hr>-->
<footer>
  <div class="footer">Copyright 2021 © Yongqi Zhang</div>
</footer>
</body>
<!-- InstanceEnd -->
</html>
